{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77343eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37,37,67,100,,,66,,14,,,22,,,,,29,19,152,9.3,104,0.7,,138,,1.8,2.7,3.9,0.7,,33.3,10.5,,16.4,,317,68.54,0,,,-0.02,38,0,17072\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '37,37,67,100,,,66,,14,,,22,,,,,29,19,152,9.3,104,0.7,,138,,1.8,2.7,3.9,0.7,,33.3,10.5,,16.4,,317,68.54,0,,,-0.02,38,0,17072'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit()  \u001b[38;5;66;03m# Replace input(\"\") with the actual input data\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Preprocess the input data\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m input_data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(value) \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m input_data]\n\u001b[0;32m     54\u001b[0m input_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([input_data])\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Apply PCA transformation to the input data\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 53\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit()  \u001b[38;5;66;03m# Replace input(\"\") with the actual input data\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Preprocess the input data\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m input_data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m input_data]\n\u001b[0;32m     54\u001b[0m input_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([input_data])\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Apply PCA transformation to the input data\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '37,37,67,100,,,66,,14,,,22,,,,,29,19,152,9.3,104,0.7,,138,,1.8,2.7,3.9,0.7,,33.3,10.5,,16.4,,317,68.54,0,,,-0.02,38,0,17072'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"sepsis-6800.csv\")\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "data = imputer.fit_transform(data)\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data[:, 2:41]\n",
    "y = data[:, 41]\n",
    "\n",
    "# Apply PCA to reduce the number of features\n",
    "pca = PCA(n_components=10)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create an SVM classifier and an MLP classifier\n",
    "svc = SVC(kernel='linear', C=1, random_state=42)\n",
    "nn = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "\n",
    "# Define the stacking classifier\n",
    "estimators = [('svc', svc), ('nn', nn)]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=MLPClassifier(), cv=5)\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Take input from the user\n",
    "input_data = input(\"\").split()  # Replace input(\"\") with the actual input data\n",
    "\n",
    "# Preprocess the input data\n",
    "input_data = [float(value) for value in input_data]\n",
    "input_data = np.array([input_data])\n",
    "\n",
    "# Apply PCA transformation to the input data\n",
    "input_data = pca.transform(input_data)\n",
    "\n",
    "# Scale the input data\n",
    "input_data = scaler.transform(input_data)\n",
    "\n",
    "# Predict the class label\n",
    "predicted_label = clf.predict(input_data)\n",
    "\n",
    "# Print the prediction\n",
    "if predicted_label == 1:\n",
    "    print(\"Sepsis\")\n",
    "else:\n",
    "    print(\"No Sepsis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6380626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"sepsis-6800.csv\")\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "data = imputer.fit_transform(data)\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data[:, 2:41]\n",
    "y = data[:, 41]\n",
    "\n",
    "# Apply PCA to reduce the number of features\n",
    "pca = PCA(n_components=10)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create an SVM classifier and an MLP classifier\n",
    "svc = SVC(kernel='linear', C=1, random_state=42)\n",
    "nn = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "\n",
    "# Define the stacking classifier\n",
    "estimators = [('svc', svc), ('nn', nn)]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=MLPClassifier(), cv=5)\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Take input from the user\n",
    "input_data = input(\"Enter the input values: \").split(\",\")  # Replace input(\"\") with the actual input data\n",
    "\n",
    "# Preprocess the input data\n",
    "input_data = [float(value) for value in input_data]\n",
    "input_data = np.array([input_data])\n",
    "\n",
    "# Apply PCA transformation to the input data\n",
    "input_data = pca.transform(input_data)\n",
    "\n",
    "# Scale the input data\n",
    "input_data = scaler.transform(input_data)\n",
    "\n",
    "# Predict the class label\n",
    "predicted_label = clf.predict(input_data)\n",
    "\n",
    "# Print the prediction\n",
    "if predicted_label == 1:\n",
    "    print(\"Sepsis\")\n",
    "else:\n",
    "    print(\"No Sepsis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as n\n",
    "import pandas as p\n",
    "from sklearn.model_selection import train_test_split as ts\n",
    "from sklearn.svm import SVC as sv\n",
    "from sklearn.neural_network import MLPClassifier as mc\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler as ss\n",
    "from sklearn.impute import SimpleImputer as si\n",
    "from sklearn.decomposition import PCA as pc\n",
    "from sklearn.ensemble import StackingClassifier as sc\n",
    "from sklearn.metrics import roc_auc_score as ras\n",
    "from sklearn.metrics import roc_curve as rc\n",
    "import matplotlib.pyplot as pl\n",
    "import seaborn as SNS\n",
    "from sklearn.ensemble import RandomForestClassifier as ranfc\n",
    "from sklearn.ensemble import AdaBoostClassifier as abc\n",
    "import tensorflow as tfl\n",
    "from tensorflow.keras.models import Sequential as sql\n",
    "from tensorflow.keras.layers import Dense as den\n",
    "\n",
    "# Load the dataset\n",
    "dat = p.read_csv(\"sepsis-6800.csv\")\n",
    "im = si(missing_values=n.nan, strategy='mean')\n",
    "dat = im.fit_transform(dat)\n",
    "\n",
    "# Split the dataset into features and target\n",
    "a = dat[:, 2:41]\n",
    "b = dat[:, 41]\n",
    "\n",
    "# Apply PCA to reduce the number of features\n",
    "prin= pc(n_components=10)\n",
    "a = prin.fit_transform(a)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "atd, atsd, btd, btsd = ts(a, b, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "sca = ss()\n",
    "atd = sca.fit_transform(atd)\n",
    "atsd = sca.transform(atsd)\n",
    "\n",
    "# Create an SVM classifier and an ANN classifier\n",
    "svc = sv(kernel='linear', C=1, random_state=42)\n",
    "nn = mc(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "\n",
    "# Define the stacking classifier\n",
    "est = [('svc', svc), ('nn', nn)]\n",
    "clf = sc(estimators=est, final_estimator=mc(), cv=5)\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(atd, btd)\n",
    "print(\"*********************************Stacking using SVM and MLP***********************************\")\n",
    "\n",
    "# Evaluate the model\n",
    "bpred = clf.predict(atsd)\n",
    "bprob = clf.predict_proba(atsd)[:, 1]\n",
    "fpr, tpr, thresholds = rc(btsd, bprob)\n",
    "print(\"Accuracy:\", accuracy_score(btsd, bpred))\n",
    "cm = confusion_matrix(btsd, bpred)\n",
    "# Convert confusion matrix to pictorial representation (heatmap)\n",
    "SNS.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "pl.xlabel(\"Predicted Labels\")\n",
    "pl.ylabel(\"True Labels\")\n",
    "pl.title(\"Confusion Matrix\")\n",
    "pl.show()\n",
    "print(bpred)\n",
    "print(classification_report(btsd,bpred))\n",
    "auc = ras(btsd, bprob)\n",
    "\n",
    "print(\"Area under the curve:\", auc)\n",
    "pl.plot(fpr, tpr)\n",
    "pl.xlabel('False Positive Rate')\n",
    "pl.ylabel('True Positive Rate')\n",
    "pl.title('ROC Curve')\n",
    "pl.show()\n",
    "\n",
    "print(\"*********************************Randomforest***********************************\")\n",
    "\n",
    "rfcl = ranfc(n_estimators=100, random_state=42)\n",
    "rfcl.fit(atd, btd)\n",
    "bpred = rfcl.predict(atsd)\n",
    "bprob = rfcl.predict_proba(atsd)[:, 1]\n",
    "fpr, tpr, thresholds = rc(btsd, bprob)\n",
    "print(\"Accuracy:\", accuracy_score(btsd, bpred))\n",
    "cm = confusion_matrix(btsd, bpred)\n",
    "# Convert confusion matrix to pictorial representation (heatmap)\n",
    "SNS.heatmap(cm, annot=True, cmap=\"Greens\", fmt=\"d\")\n",
    "pl.xlabel(\"Predicted Labels\")\n",
    "pl.ylabel(\"True Labels\")\n",
    "pl.title(\"Confusion Matrix\")\n",
    "pl.show()\n",
    "print(bpred)\n",
    "print(classification_report(btsd,bpred))\n",
    "auc = ras(btsd, bprob)\n",
    "\n",
    "print(\"Area under the curve:\", auc)\n",
    "pl.plot(fpr, tpr)\n",
    "pl.xlabel('False Positive Rate')\n",
    "pl.ylabel('True Positive Rate')\n",
    "pl.title('ROC Curve')\n",
    "pl.show()\n",
    "\n",
    "\n",
    "print(\"*********************************AdaboostClassifier***********************************\")\n",
    "\n",
    "rfcl = abc(n_estimators=100, random_state=42)\n",
    "rfcl.fit(atd, btd)\n",
    "bpred = rfcl.predict(atsd)\n",
    "bprob = rfcl.predict_proba(atsd)[:, 1]\n",
    "fpr, tpr, thresholds = rc(btsd, bprob)\n",
    "print(\"Accuracy:\", accuracy_score(btsd, bpred))\n",
    "cm = confusion_matrix(btsd, bpred)\n",
    "# Convert confusion matrix to pictorial representation (heatmap)\n",
    "SNS.heatmap(cm, annot=True, cmap=\"Oranges\", fmt=\"d\")\n",
    "pl.xlabel(\"Predicted Labels\")\n",
    "pl.ylabel(\"True Labels\")\n",
    "pl.title(\"Confusion Matrix\")\n",
    "pl.show()\n",
    "print(bpred)\n",
    "print(classification_report(btsd,bpred))\n",
    "auc = ras(btsd, bprob)\n",
    "\n",
    "print(\"Area under the curve:\", auc)\n",
    "pl.plot(fpr, tpr)\n",
    "pl.xlabel('False Positive Rate')\n",
    "pl.ylabel('True Positive Rate')\n",
    "pl.title('ROC Curve')\n",
    "pl.show()\n",
    "\n",
    "\n",
    "\n",
    "print(\"**********************************ANN Classifier**********************************\")\n",
    "mo = sql()\n",
    "mo.add(den(64, activation='relu', input_shape=(atd.shape[1],)))\n",
    "mo.add(den(64, activation='relu'))\n",
    "mo.add(den(1, activation='sigmoid'))\n",
    "mo.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "mo.fit(atd,btd, epochs=30, batch_size=32, verbose=1)\n",
    "los, accur = mo.evaluate(atsd, btsd)\n",
    "print(\"Accuracy:\", accur)\n",
    "bprob = mo.predict(atsd)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "bpred = n.round(bprob).flatten()\n",
    "fpr, tpr, thresholds = rc(btsd, bprob)\n",
    "\n",
    "cm = confusion_matrix(btsd, bpred)\n",
    "# Convert confusion matrix to pictorial representation (heatmap)\n",
    "SNS.heatmap(cm, annot=True, cmap=\"Reds\", fmt=\"d\")\n",
    "pl.xlabel(\"Predicted Labels\")\n",
    "pl.ylabel(\"True Labels\")\n",
    "pl.title(\"Confusion Matrix\")\n",
    "pl.show()\n",
    "print(bpred)\n",
    "print(classification_report(btsd,bpred))\n",
    "auc = ras(btsd, bprob)\n",
    "\n",
    "print(\"Area under the curve:\", auc)\n",
    "pl.plot(fpr, tpr)\n",
    "pl.xlabel('False Positive Rate')\n",
    "pl.ylabel('True Positive Rate')\n",
    "pl.title('ROC Curve')\n",
    "pl.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc983f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
